{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa70d320-ac9c-4e9a-b73e-3313b56323c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80c262bd-f535-4f22-9b08-455584f9eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/1975_Pacific_hurricane_season'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3271a118-1a8a-46be-ad37-1fe3d04948c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize lists to store the scraped data\n",
    "hurricane_names = []\n",
    "date_start = []\n",
    "date_end = []\n",
    "num_deaths = []\n",
    "areas_affected = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c032fff8-faa3-4133-b0a9-da53d4dc3e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Scrape hurricane names\n",
    "name_headers = soup.find_all(class_='mw-heading mw-heading3')\n",
    "for header in name_headers:\n",
    "    name = header.text.replace('[edit]', '').strip()  # Remove [edit] from the name\n",
    "    hurricane_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dcb30be-d479-4bda-8bdc-54850936f0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Scrape the date ranges (start and end dates)\n",
    "infoboxes = soup.find_all('td', {'class': 'infobox-data'})\n",
    "for box in infoboxes:\n",
    "    if '–' in box.text:\n",
    "        # Split the start and end dates by '–'\n",
    "        date_range = box.text.split('–')\n",
    "        if len(date_range) == 2:\n",
    "            date_start.append(date_range[0].strip())\n",
    "            date_end.append(date_range[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf26cfc1-42c3-4d62-ad05-137217baa6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Deaths: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '30', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "num_deaths = []\n",
    "\n",
    "# Find all the sections with the class 'mw-heading mw-heading3'\n",
    "headings = soup.find_all('div', class_='mw-heading mw-heading3')\n",
    "\n",
    "# Iterate over each heading\n",
    "for heading in headings:\n",
    "    # Find the next sibling after the heading to start searching for content\n",
    "    start = heading.find_next_sibling()\n",
    "\n",
    "    # Continue until the next heading or the end of the document\n",
    "    while start:\n",
    "        # If another heading is encountered, stop this section\n",
    "        if start.name == 'div' and 'mw-heading' in start.get('class', []):\n",
    "            break\n",
    "\n",
    "        # If the sibling is a paragraph, process it\n",
    "        if start.name == 'p':\n",
    "            text = start.text.lower()\n",
    "            num = '0'  # Default to 0 if no match is found\n",
    "\n",
    "            # Look for phrases like \"killed X\", \"X fatalities\", or \"X deaths\"\n",
    "            match = re.search(r'(?:killed\\s+(\\d+)\\s+people)|(\\d+)\\s+(fatalities|deaths)', text)\n",
    "            if match:\n",
    "                if match.group(1):  \n",
    "                    num = match.group(1)\n",
    "                elif match.group(2):  \n",
    "                    num = match.group(2)\n",
    "                    \n",
    "            num_deaths.append(num)\n",
    "            break  # Stop after processing the first paragraph\n",
    "\n",
    "        # Move to the next sibling in the document\n",
    "        start = start.find_next_sibling()\n",
    "\n",
    "# Print the result for verification\n",
    "print(\"Number of Deaths:\", num_deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68563072-1fcd-4f15-b307-930362173b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Areas affected: ['south of the tres marias islands', 'south of the tip of the baja', 'south of acapulco', 'no areas', 'south of acapulco', 'no areas', 'west of cabo san lucas', 'no areas', 'south of the gulf of tehuantepec', 'south of acapulco', 'no areas', 'south of alaska', 'south of manzanillo', 'eastern pacific ocean', 'no areas', 'south of mexico', 'no areas', 'eastern pacific']\n"
     ]
    }
   ],
   "source": [
    "areas_affected = []\n",
    "\n",
    "# Find all the sections with the class 'mw-heading mw-heading3'\n",
    "headings = soup.find_all('div', class_='mw-heading mw-heading3')\n",
    "\n",
    "# List of directions to look for\n",
    "directions = ['south of', 'north of', 'east of', 'west of', 'northeast of', 'northwest of', 'southeast of', 'southwest of', 'eastern']\n",
    "\n",
    "stop_after_second_word = ['lily', 'organized','and']\n",
    "stop_at_fifth_word = 'organized'\n",
    "stop_at_fifth_word = 'from'\n",
    "\n",
    "# Iterate over each heading\n",
    "for heading in headings:\n",
    "    # Find the next sibling after the heading to start searching for content\n",
    "    start = heading.find_next_sibling()\n",
    "\n",
    "    # Continue until the next heading or the end of the document\n",
    "    while start:\n",
    "        # If another heading is encountered, stop this section\n",
    "        if start.name == 'div' and 'mw-heading' in start.get('class', []):\n",
    "            break\n",
    "\n",
    "        # If the sibling is a paragraph, process it\n",
    "        if start.name == 'p':\n",
    "            text = start.text.lower()\n",
    "            areas_text = 'no areas'  # Default to 'no areas' if no match found\n",
    "            \n",
    "            # Iterate through each direction to find a match in the text\n",
    "            for direction in directions:\n",
    "                if direction in text:\n",
    "                    # Split the paragraph into sentences\n",
    "                    sentences = text.split('.')\n",
    "                    \n",
    "                    # Search each sentence for the direction\n",
    "                    for sentence in sentences:\n",
    "                        if direction in sentence:\n",
    "                            # Find the part of the sentence after the direction\n",
    "                            location_part = sentence.split(direction)[-1].strip()\n",
    "                            # Split the part after direction into words\n",
    "                            location_words = location_part.split()\n",
    "\n",
    "                            # Initialize a list to hold the selected words\n",
    "                            selected_words = []\n",
    "                            \n",
    "                            # Loop through the words (up to 5) and apply conditions\n",
    "                            for idx, word in enumerate(location_words[:5]):\n",
    "                                selected_words.append(word)\n",
    "\n",
    "                                # Stop early if the second word is in stop_after_second_word\n",
    "                                if idx == 1 and word in stop_after_second_word:\n",
    "                                    selected_words = selected_words[:1]  # Only keep the first word after direction\n",
    "                                    break\n",
    "\n",
    "                                # Stop early if the fourth word is in stop_after_second_word\n",
    "                                if idx == 3 and word in stop_after_second_word:\n",
    "                                    selected_words = selected_words[:3]  # Keep up to the third word\n",
    "                                    break\n",
    "\n",
    "                                # Stop early if the fifth word is 'from'\n",
    "                                if idx == 4 and word == stop_at_fifth_word:\n",
    "                                    selected_words = selected_words[:4]  # Keep up to the fourth word\n",
    "                                    break\n",
    "                            \n",
    "                            # Join the direction with the selected words\n",
    "                            areas_text = f\"{direction} \" + ' '.join(selected_words)\n",
    "                            break  # Break after finding the first match\n",
    "                    break  # Break after finding the first matching direction\n",
    "            \n",
    "            # Append the areas affected to the list (default is 'no areas')\n",
    "            areas_affected.append(areas_text)\n",
    "            break\n",
    "\n",
    "        # Move to the next sibling in the document\n",
    "        start = start.find_next_sibling()\n",
    "\n",
    "# Print the result for verification\n",
    "print(\"Areas affected:\", areas_affected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77209a1f-1b2c-4666-be9d-0f553202a053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 17 17 18 18\n"
     ]
    }
   ],
   "source": [
    "print(len(hurricane_names), len(date_start), len(date_end), len(num_deaths), len(areas_affected))\n",
    "max_len = max(len(hurricane_names), len(date_start), len(date_end), len(num_deaths), len(areas_affected))\n",
    "hurricane_names += ['N/A'] * (max_len - len(hurricane_names))\n",
    "date_start += ['N/A'] * (max_len - len(date_start))\n",
    "date_end += ['N/A'] * (max_len - len(date_end))\n",
    "num_deaths += ['0'] * (max_len - len(num_deaths))\n",
    "areas_affected += ['no areas'] * (max_len - len(areas_affected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb41d3d7-e6fa-4963-98ca-d67d1befd9b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 8: Structure the data into a DataFrame\n",
    "data = {\n",
    "    'Hurricane Storm Name': hurricane_names,\n",
    "    'Start Date': date_start,\n",
    "    'End Date': date_end,\n",
    "    'Number of Deaths': num_deaths,\n",
    "    'Areas Affected': areas_affected,\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9261c280-6974-4daf-958e-4705f09bc412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Hurricane Storm Name    Start Date      End Date Number of Deaths  \\\n",
      "0           Hurricane Agatha        June 2        June 5                0   \n",
      "1     Tropical Storm Bridget       June 28        July 3                0   \n",
      "2         Hurricane Carlotta        July 2       July 11                0   \n",
      "3           Hurricane Denise        July 5       July 15                0   \n",
      "4     Tropical Storm Eleanor       July 10       July 12                0   \n",
      "5    Tropical Storm Francene       July 27       July 30                0   \n",
      "6   Tropical Storm Georgette     August 11     August 14                0   \n",
      "7      Tropical Storm Hilary     August 13     August 17                0   \n",
      "8             Hurricane Ilsa     August 18     August 26                0   \n",
      "9            Hurricane Jewel     August 24     August 31                0   \n",
      "10         Hurricane Katrina     August 29   September 7                0   \n",
      "11         Unnamed hurricane     August 31   September 5                0   \n",
      "12            Hurricane Lily  September 16  September 21                0   \n",
      "13     Tropical Storm Monica  September 28     October 2                0   \n",
      "14    Tropical Storm Nanette  September 28     October 4                0   \n",
      "15          Hurricane Olivia    October 22    October 25               30   \n",
      "16  Tropical Storm Priscilla    November 2    November 7                0   \n",
      "17             Other systems           N/A           N/A                0   \n",
      "\n",
      "                      Areas Affected  \n",
      "0   south of the tres marias islands  \n",
      "1       south of the tip of the baja  \n",
      "2                  south of acapulco  \n",
      "3                           no areas  \n",
      "4                  south of acapulco  \n",
      "5                           no areas  \n",
      "6             west of cabo san lucas  \n",
      "7                           no areas  \n",
      "8   south of the gulf of tehuantepec  \n",
      "9                  south of acapulco  \n",
      "10                          no areas  \n",
      "11                   south of alaska  \n",
      "12               south of manzanillo  \n",
      "13             eastern pacific ocean  \n",
      "14                          no areas  \n",
      "15                   south of mexico  \n",
      "16                          no areas  \n",
      "17                   eastern pacific  \n"
     ]
    }
   ],
   "source": [
    "# Step 9: Save the DataFrame to a CSV file\n",
    "df.to_csv('1975_Pacific_hurricane_season.csv', index=False)\n",
    "\n",
    "# Print a sample of the DataFrame to verify\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a632934d-3406-4cd1-921f-c9c094530cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Hurricane Storm Name    Start Date      End Date Number of Deaths  \\\n",
      "0           Hurricane Agatha        June 2        June 5                0   \n",
      "1     Tropical Storm Bridget       June 28        July 3                0   \n",
      "2         Hurricane Carlotta        July 2       July 11                0   \n",
      "3           Hurricane Denise        July 5       July 15                0   \n",
      "4     Tropical Storm Eleanor       July 10       July 12                0   \n",
      "5    Tropical Storm Francene       July 27       July 30                0   \n",
      "6   Tropical Storm Georgette     August 11     August 14                0   \n",
      "7      Tropical Storm Hilary     August 13     August 17                0   \n",
      "8             Hurricane Ilsa     August 18     August 26                0   \n",
      "9            Hurricane Jewel     August 24     August 31                0   \n",
      "10         Hurricane Katrina     August 29   September 7                0   \n",
      "11         Unnamed hurricane     August 31   September 5                0   \n",
      "12            Hurricane Lily  September 16  September 21                0   \n",
      "13     Tropical Storm Monica  September 28     October 2                0   \n",
      "14    Tropical Storm Nanette  September 28     October 4                0   \n",
      "15          Hurricane Olivia    October 22    October 25               30   \n",
      "16  Tropical Storm Priscilla    November 2    November 7                0   \n",
      "17             Other systems           N/A           N/A                0   \n",
      "\n",
      "                      Areas Affected  \n",
      "0   south of the tres marias islands  \n",
      "1       south of the tip of the baja  \n",
      "2                  south of acapulco  \n",
      "3                           no areas  \n",
      "4                  south of acapulco  \n",
      "5                           no areas  \n",
      "6             west of cabo san lucas  \n",
      "7                           no areas  \n",
      "8   south of the gulf of tehuantepec  \n",
      "9                  south of acapulco  \n",
      "10                          no areas  \n",
      "11                   south of alaska  \n",
      "12               south of manzanillo  \n",
      "13             eastern pacific ocean  \n",
      "14                          no areas  \n",
      "15                   south of mexico  \n",
      "16                          no areas  \n",
      "17                   eastern pacific  \n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
